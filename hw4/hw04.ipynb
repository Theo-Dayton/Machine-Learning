{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name and ID\n",
    "Theo Dayton 1325139"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW04 Code\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 04 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file (`hw04.ipynb`), `implementation.py`, and two files for both trees images, i.e., `full`, `full.pdf`, `simple`, and `simple.pdf` (PDFs and text files generated using `graphviz` within the code). HINT: `render()`, and it should be clear when to use it, i.e., #3). Compress all files mentioned and submit to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/class/lcwv1h9p2a11ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import required libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from implementation import information_remainder, counting_heuristic, set_entropy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You should start by computing the two heuristic values for the toy data described in the assignment handout. You should then load the two versions of the abalone data, compute the two heuristic values on features (for the simplified data), and then build decision trees for each set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Compute both heuristics for toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "feature_names = np.array([\"A\", \"B\"])\n",
    "feature_len = 2\n",
    "classes = [0, 1]\n",
    "\n",
    "x_set = np.array([[1, 1], [1, 1], [0, 1], [0, 0],\n",
    "        [0, 1], [0, 0], [0, 0], [0, 0]])\n",
    "y_set = np.array([0, 0, 0, 0, 1, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 6/8\n",
      "B: 6/8\n"
     ]
    }
   ],
   "source": [
    "sort_correct = []\n",
    "sort_names = [\"A\", \"B\"]\n",
    "\n",
    "correct_counts = []\n",
    "\n",
    "for feature_index in range(x_set.shape[1]):\n",
    "    correct_count = counting_heuristic(x_set, y_set, feature_index, classes)\n",
    "    correct_counts.append(correct_count)\n",
    "\n",
    "sort_correct = sorted(correct_counts, reverse=True)\n",
    "\n",
    "\n",
    "# Print the sorted features along with their correct predictions count in the smaller dataset\n",
    "longest = max(len(name) for name in sort_names)\n",
    "for name, correct in zip(sort_names, sort_correct):\n",
    "    print(\"%*s: %d/%d\" % (longest, name, correct, len(x_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discussion of results.\n",
    "\n",
    "For the counting heuristic, the feature with the highest count is chosen as the starting feature. The reason for this is that the feature with the highest count is the most informative feature to spit the data, since it has the highest predictive power. With regards to the information gain heuristic, the feature with the highest gain is chosen as the starting feature. The reason for this is that a higher information gain means less entropy, and therefore, less uncertainty, which can lead to a more accurate tree.\n",
    "Using different heuristics will result in different starting features, which affect the entire tree. Heuristics also affect the accuracy of the decision tree, since different heuristics will prioritize different types of features. The counting heuristic does not consider the entropy of the data, but it is very efficient computation-wise. The information gain heuristic will prioritize features that maximize the reduction in entropy, which will most likely lead to more accurate decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0.311\n",
      "B: 0.189\n"
     ]
    }
   ],
   "source": [
    "sort_gains = []\n",
    "sort_names_by_gains = []\n",
    "\n",
    "for feature_index in range(x_set.shape[1]):\n",
    "    gain = information_remainder(x_set, y_set, feature_index, classes)\n",
    "    sort_gains.append(gain)\n",
    "    sort_names_by_gains.append(feature_names[feature_index])\n",
    "\n",
    "sort_names_by_gains = sorted(sort_names_by_gains)\n",
    "sort_gains.sort(reverse=True)\n",
    "\n",
    "longest = max(len(name) for name in sort_names_by_gains)\n",
    "for name, gain in zip(sort_names_by_gains, sort_gains):\n",
    "    print(\"%*s: %.3f\" % (longest, name, gain))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Compute both heuristics for simplified abalone data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# load the data into np arrays\n",
    "\n",
    "# full-feature abalone data\n",
    "x_train_df = pd.read_csv('data_abalone/x_train.csv')\n",
    "x_train = x_train_df.to_numpy()\n",
    "\n",
    "x_test_df = pd.read_csv('data_abalone/x_test.csv')\n",
    "x_test = x_test_df.to_numpy()\n",
    "\n",
    "y_train_df = pd.read_csv('data_abalone/y_train.csv')\n",
    "y_train = y_train_df.to_numpy()\n",
    "\n",
    "y_test_df = pd.read_csv('data_abalone/y_test.csv')\n",
    "y_test = y_test_df.to_numpy()\n",
    "\n",
    "\n",
    "# simplified version of the data (Restricted-feature)\n",
    "\n",
    "simple_x_train_df = pd.read_csv('data_abalone/small_binary_x_train.csv')\n",
    "simple_x_train = simple_x_train_df.to_numpy()\n",
    "\n",
    "simple_x_test_df = pd.read_csv('data_abalone/small_binary_x_test.csv')\n",
    "simple_x_test = simple_x_test_df.to_numpy()\n",
    "\n",
    "simple_y_train_df = pd.read_csv('data_abalone/3class_y_train.csv')\n",
    "simple_y_train = simple_y_train_df.to_numpy()\n",
    "\n",
    "simple_y_test_df = pd.read_csv('data_abalone/3class_y_test.csv')\n",
    "simple_y_test = simple_x_test_df.to_numpy()\n",
    "\n",
    "# get useful information\n",
    "full_feature_names = list(x_train_df.columns)# features names of full-feature abalone data\n",
    "simple_feature_names = list(simple_x_train_df.columns)# features names of restricted-feature data\n",
    "classes_abalone = np.unique(np.concatenate((y_train, y_test))) # unique set of class labels\n",
    "class_names_dict = {0: 'Small', 1: 'Medium', 2: 'Large'}\n",
    "class_names = ['Small', 'Medium', 'Large'] # name of the classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  diam_mm: 1529/3176\n",
      "height_mm: 1529/3176\n",
      "  is_male: 1529/3176\n",
      "length_mm: 1529/3176\n"
     ]
    }
   ],
   "source": [
    "sort_correct_abalone = []\n",
    "sort_names_abalone = sorted(simple_feature_names)\n",
    "correct_counts = []\n",
    "\n",
    "for i, feature_name in enumerate(simple_feature_names):\n",
    "    correctness_count = counting_heuristic(simple_x_train, simple_y_train, i, classes_abalone)\n",
    "    sort_correct_abalone.append(correctness_count)\n",
    "    sort_names_abalone.append(feature_name)\n",
    "\n",
    "sort_names_abalone = [name for _, name in sorted(zip(sort_correct_abalone, sort_names_abalone))]\n",
    "\n",
    "sort_correct_abalone.sort(reverse=True)\n",
    "\n",
    "\n",
    "# Print the sorted features along with their correct predictions count in the smaller dataset\n",
    "longest = max(len(name) for name in sort_names_abalone)\n",
    "for name, correct in zip(sort_names_abalone, sort_correct_abalone):\n",
    "    print(\"%*s: %d/%d\" % (longest, name, correct, len(simple_x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: 0.173\n",
      "  diam_mm: 0.150\n",
      "length_mm: 0.135\n",
      "  is_male: 0.025\n"
     ]
    }
   ],
   "source": [
    "sort_gains_abalone = []\n",
    "sort_names_by_gains_abalone = simple_feature_names\n",
    "\n",
    "for feature_index in range(simple_x_train.shape[1]):\n",
    "    gain = information_remainder(simple_x_train, simple_y_train, feature_index, classes_abalone)\n",
    "    sort_gains_abalone.append(gain)\n",
    "\n",
    "sort_names_by_gains_abalone = [x for _, x in sorted(zip(sort_gains_abalone, sort_names_by_gains_abalone), key=lambda pair: pair[0], reverse=True)]\n",
    "sort_gains_abalone.sort(reverse=True)\n",
    "\n",
    "\n",
    "longest = max(len(name) for name in sort_names_by_gains_abalone)\n",
    "for name, gain in zip(sort_names_by_gains_abalone, sort_gains_abalone):\n",
    "    print(\"%*s: %.3f\" % (longest, name, gain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Generate decision trees (criterion='entropy', random_state=42) for full- and simple-feature data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (a) Train and eval on entire train and test sets. Print accuracy values and generate tree images.\n",
    "\n",
    "Render the tree diagram, naming it \"full.\" A text file and PDF should be created and saved (i.e., `full` and `full.pdf`) - include both in submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 1.000\n",
      "Accuracy  (test): 0.204\n"
     ]
    },
    {
     "data": {
      "text/plain": "'full.pdf'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "dtc_abalone = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dtc_abalone.fit(x_train, y_train)\n",
    "\n",
    "train_accuracy = dtc_abalone.score(x_train, y_train) # Fix me\n",
    "test_accuracy = dtc_abalone.score(x_test, y_test) # Fix me\n",
    "print(f\"Accuracy (train): {train_accuracy:.3f}\")\n",
    "print(f\"Accuracy  (test): {test_accuracy:.3f}\")\n",
    "\n",
    "full_data = tree.export_graphviz(dtc_abalone, out_file=None, feature_names=full_feature_names)\n",
    "graph = graphviz.Source(full_data)\n",
    "graph.render(\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (b) Restricted-feature (aka simple) data.\n",
    "Train and eval on simple train and test sets. Same as above, accept this time use the `simple` set. Render the tree diagram, naming it \"simple.\" A text file and PDF should be created and saved (i.e., `simple` and `simple.pdf`) - include both in submission."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 0.733\n",
      "Accuracy  (test): 1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": "'simple.pdf'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_simple = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dtc_simple.fit(simple_x_train, simple_y_train)\n",
    "\n",
    "simple_train_accuracy = dtc_simple.score(simple_x_train, simple_y_train) # Fix me\n",
    "print(f\"Accuracy (train): {simple_train_accuracy:.3f}\")\n",
    "\n",
    "dtc_simple2 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dtc_simple2.fit(simple_x_test, simple_y_test)\n",
    "simple_test_accuracy = dtc_simple2.score(simple_x_test, simple_y_test) # Fix me\n",
    "print(f\"Accuracy  (test): {simple_test_accuracy:.3f}\")\n",
    "\n",
    "simple_data = tree.export_graphviz(dtc_simple, out_file=None, feature_names=simple_feature_names, class_names=class_names)\n",
    "graph = graphviz.Source(simple_data)\n",
    "graph.render(\"simple\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discuss the results seen for the two trees\n",
    "\n",
    "First, we can discuss  the results that we achieved from decision trees. Regarding accuracy, we see that the accuracy on the simple training data is lower compared to the full dataset. This can be explained as the simpler data is simply not complex enough to achieve good performance. However, the accuracy on the test data is higher for the simple dataset. This can be explained since a simple model generalizes better to unseen data.\n",
    "With regards to the actual tree structures, it is clear that the simplified dataset resulted in a much less complex tree structure, as the splits needed to classify the data is much less, since the number of features is less.\n",
    "Regarding errors, there are some leaves where the samples are only 13, while others are as high as 934. This tells us that there is an imbalance, since there are imbalanced splits. This is found in other nodes as well, not only the leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
